{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMu+PaAz+xWeRBRpDKUHXAm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CoderFalconX/Tortoise-tts-gradio-ui/blob/main/Tortoise%20TTS_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y transformers tokenizers\n",
        "\n",
        "!pip install --no-cache-dir numpy==1.26.4 numba==0.59.1 scipy==1.11.4\n",
        "\n",
        "!pip install --no-cache-dir transformers==4.41.2 tokenizers==0.19.1 \\\n",
        "  einops==0.4.1 rotary-embedding-torch==0.3.6 \\\n",
        "  Unidecode==1.4.0 librosa==0.10.2.post1 resampy soundfile \\\n",
        "  progressbar2 ffmpeg-python accelerate==0.26.0"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Yay26fudosNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the official Tortoise TTS repo\n",
        "!git clone https://github.com/neonbjb/tortoise-tts.git"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xja8_6wspCVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/tortoise-tts\")\n",
        "\n",
        "from tortoise.api import TextToSpeech\n",
        "from tortoise.utils.audio import load_voice\n",
        "\n",
        "print(\"‚úÖ Tortoise import successful\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vWzXUz0CpG2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "base = \"/content/tortoise-tts/tortoise/voices\"\n",
        "print(\"Voices base exists:\", os.path.isdir(base), base)\n",
        "print(\"Existing voices:\", [d for d in os.listdir(base)] if os.path.isdir(base) else [])\n",
        "\n",
        "# also show any audio files you might have anywhere under /content\n",
        "cands = glob.glob(\"/content/**/*.*\", recursive=True)\n",
        "cand_audio = [p for p in cands if p.lower().endswith((\".wav\",\".mp3\",\".m4a\",\".flac\",\".ogg\"))]\n",
        "print(\"Found audio files:\", len(cand_audio))\n",
        "for p in cand_audio[:20]:\n",
        "    print(\" -\", p)\n",
        "\n",
        "!rm -rf /content/tortoise-tts/tortoise/voices/myself\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DAp_yIrDpRC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt -y install ffmpeg >/dev/null\n",
        "!pip -q install pydub\n",
        "\n",
        "from google.colab import files\n",
        "from pydub import AudioSegment, effects\n",
        "from pydub.utils import make_chunks\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "import os, glob\n",
        "\n",
        "voice_dir = \"/content/tortoise-tts/tortoise/voices/myvoice\"\n",
        "os.makedirs(voice_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "fname, data = next(iter(uploaded.items()))\n",
        "audio = AudioSegment.from_file(BytesIO(data))\n",
        "audio = effects.normalize(audio)\n",
        "\n",
        "\n",
        "chunk_ms = 15_000\n",
        "\n",
        "chunks = make_chunks(audio, chunk_ms)\n",
        "\n",
        "count = 0\n",
        "for i, ch in enumerate(chunks, start=1):\n",
        "    if ch.dBFS < -35:\n",
        "        continue\n",
        "    prepared = ch.set_frame_rate(22050).set_channels(1).set_sample_width(2)\n",
        "    out = Path(voice_dir) / f\"clip_{i:03d}.wav\"\n",
        "    prepared.export(out.as_posix(), format=\"wav\")\n",
        "    print(f\"Saved: {out} | duration: {len(prepared)/1000:.2f}s\")\n",
        "    count += 1\n",
        "\n",
        "print(f\"\\nToplam kaydedilen klip: {count}\")\n",
        "print(\"\\nKayƒ±tlƒ± klipler:\")\n",
        "for p in glob.glob(voice_dir + \"/*.wav\"):\n",
        "    print(\" -\", p)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dy1Ad7Uhpl6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, uuid, tempfile, traceback\n",
        "import torch, torchaudio, gradio as gr\n",
        "from tortoise.api import TextToSpeech\n",
        "from tortoise.utils.audio import load_audio\n",
        "\n",
        "VOICES_ROOT = \"/content/tortoise-tts/tortoise/voices\"\n",
        "SAMPLE_RATE = 22050\n",
        "TTS = TextToSpeech()\n",
        "\n",
        "# --- SAVE helper (robust) ---\n",
        "def _to_1xN(t: torch.Tensor) -> torch.Tensor:\n",
        "    t = t.detach().cpu()\n",
        "    if t.ndim == 1:\n",
        "        t = t.unsqueeze(0)\n",
        "    elif t.ndim > 2:\n",
        "        t = t.reshape(1, -1)\n",
        "    return t.to(torch.float32)\n",
        "\n",
        "def save_wav_tensor(wav, path, sr=SAMPLE_RATE):\n",
        "    if isinstance(wav, (list, tuple)):\n",
        "        wav = torch.cat([_to_1xN(w) for w in wav if w is not None], dim=1)\n",
        "    elif isinstance(wav, torch.Tensor):\n",
        "        wav = _to_1xN(wav)\n",
        "    else:\n",
        "        wav = _to_1xN(torch.tensor(wav))\n",
        "    maxabs = wav.abs().max()\n",
        "    if maxabs > 1.0:\n",
        "        wav = wav / maxabs\n",
        "    torchaudio.save(path, wav, sr)\n",
        "\n",
        "# --- VOICE UTILS ---\n",
        "def list_voice_dirs():\n",
        "    if not os.path.isdir(VOICES_ROOT):\n",
        "        return []\n",
        "    return sorted([d for d in os.listdir(VOICES_ROOT)\n",
        "                   if os.path.isdir(os.path.join(VOICES_ROOT, d))])\n",
        "\n",
        "def load_voice_samples(folder):\n",
        "    path = os.path.join(VOICES_ROOT, folder)\n",
        "    if not os.path.isdir(path):\n",
        "        return [], []\n",
        "    files = sorted([f for f in os.listdir(path) if f.lower().endswith((\".wav\", \".mp3\"))])\n",
        "    samples, cond_latents = [], []\n",
        "    for f in files:\n",
        "        s = load_audio(os.path.join(path, f), SAMPLE_RATE)\n",
        "        if s.ndim == 1:\n",
        "            s = s.unsqueeze(0)\n",
        "        samples.append(s)\n",
        "    return samples, None  # cond_latents is optional, Tortoise handles None\n",
        "\n",
        "# --- CORE GEN ---\n",
        "def generate(text, folder, preset):\n",
        "    try:\n",
        "        voice_samples, cond_latents = load_voice_samples(folder)\n",
        "        if not voice_samples:\n",
        "            return None, f\"‚ùå No audio in voices/{folder}\"\n",
        "\n",
        "        wav = TTS.tts_with_preset(\n",
        "            text=text,\n",
        "            voice_samples=voice_samples,\n",
        "            conditioning_latents=cond_latents,\n",
        "            preset=preset\n",
        "        )\n",
        "        if wav is None or (isinstance(wav, (list, tuple)) and len(wav) == 0):\n",
        "            return None, \"‚ùå Model returned no audio. Try shorter text or lower quality.\"\n",
        "\n",
        "        out_path = os.path.join(tempfile.gettempdir(), f\"tts_{uuid.uuid4().hex}.wav\")\n",
        "        save_wav_tensor(wav, out_path, SAMPLE_RATE)\n",
        "        return out_path, f\"‚úÖ Generated: {out_path}\"\n",
        "    except Exception as e:\n",
        "        return None, f\"‚ùå Error: {e}\\n\\n{traceback.format_exc()}\"\n",
        "\n",
        "# --- APPLY PITCH AFTER ---\n",
        "def apply_pitch(file_path, semitones):\n",
        "    try:\n",
        "        if not file_path:\n",
        "            return None, \"‚ö†Ô∏è Generate audio first.\"\n",
        "        wav, sr = torchaudio.load(file_path)\n",
        "        wav_shifted = torchaudio.functional.pitch_shift(wav, sr, n_steps=int(semitones))\n",
        "        out_path = os.path.join(tempfile.gettempdir(), f\"pitch_{uuid.uuid4().hex}.wav\")\n",
        "        save_wav_tensor(wav_shifted, out_path, sr)\n",
        "        return out_path, f\"‚úÖ Pitch applied ({semitones:+} semitones): {out_path}\"\n",
        "    except Exception as e:\n",
        "        return None, f\"‚ùå Pitch error: {e}\\n\\n{traceback.format_exc()}\"\n",
        "\n",
        "# --- UI ---\n",
        "with gr.Blocks(title=\"Tortoise TTS\") as demo:\n",
        "    gr.Markdown(\"## üéôÔ∏è Generate with Tortoise TTS, then adjust pitch separately\")\n",
        "\n",
        "    text = gr.Textbox(lines=6, label=\"Text\", value=\"Hello world!\")\n",
        "    preset = gr.Dropdown([\"ultra_fast\",\"fast\",\"standard\",\"high_quality\"],\n",
        "                         value=\"fast\", label=\"Quality\")\n",
        "    folder = gr.Dropdown(list_voice_dirs(), label=\"Voice Folder\",\n",
        "                         value=(list_voice_dirs()[0] if list_voice_dirs() else None))\n",
        "\n",
        "    gen_btn = gr.Button(\"üöÄ Generate Audio\")\n",
        "    audio_out = gr.Audio(type=\"filepath\", label=\"Generated Audio\", show_download_button=True)\n",
        "    log_out = gr.Textbox(lines=6, label=\"Logs\", interactive=False)\n",
        "\n",
        "    # Pitch section\n",
        "    pitch_slider = gr.Slider(minimum=-12, maximum=12, step=1, value=0, label=\"Pitch shift (semitones)\")\n",
        "    pitch_btn = gr.Button(\"üéöÔ∏è Apply Pitch to Generated Audio\")\n",
        "    audio_pitch = gr.Audio(type=\"filepath\", label=\"Pitch-shifted Audio\", show_download_button=True)\n",
        "    log_pitch = gr.Textbox(lines=4, label=\"Pitch Logs\", interactive=False)\n",
        "\n",
        "    gen_btn.click(generate, [text, folder, preset], [audio_out, log_out])\n",
        "    pitch_btn.click(apply_pitch, [audio_out, pitch_slider], [audio_pitch, log_pitch])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "WK7eiBK-Ubog"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}